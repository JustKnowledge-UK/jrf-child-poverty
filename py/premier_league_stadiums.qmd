---
title: "Untitled"
format: html
---


```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
import contextily as cx
from adjustText import adjust_text
import configparser
import psycopg2
import os
import pickle

config = configparser.ConfigParser()
config.read(os.path.join('..', 'db_config.ini'))

db_params = dict(config['postgresql'])
```

Read the table on wikipedia: [https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums](https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums)

```{python}
# Define the URL
url = "https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums"

# Send GET request to the webpage
response = requests.get(url)
response.raise_for_status()  # Raise an exception for bad status codes

# Parse the HTML content
soup = BeautifulSoup(response.content, 'html.parser')

# Find the first wikitable (which contains the stadiums data)
table = soup.find('table', {'class': 'wikitable'})

# Extract table data using pandas
stadiums_df = pd.read_html(str(table))[0]

# Clean the data
def clean_text(text):
    """Remove Wikipedia reference numbers and extra whitespace"""
    if pd.isna(text):
        return text
    # Remove reference numbers like [1], [2], etc.
    text = re.sub(r'\[.*?\]', '', str(text))
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Apply cleaning to all columns
for col in stadiums_df.columns:
    stadiums_df[col] = stadiums_df[col].apply(clean_text)

# Remove any completely empty rows
stadiums_df = stadiums_df.dropna(how='all')

# Display basic info about the scraped data
print(f"Successfully scraped {len(stadiums_df)} stadiums")
print(f"Columns: {', '.join(stadiums_df.columns)}")
print("\nFirst few rows:")
print(stadiums_df.head())

# Display data types and info
print("\nDataFrame info:")
print(stadiums_df.info())

# Optional: Save to CSV
stadiums_df.to_csv('premier_league_stadiums.csv', index=False)
print("\nData saved to 'premier_league_stadiums.csv'")

# Parse the coordinates into usable WGS64 geometries
def parse_coordinates(coord_str):
    """
    Convert coordinates to decimal degrees (WGS84)
    Handles format: 53°25′51″N 002°57′39″W﻿ / ﻿53.43083°N 2.96083°W
    """
    if pd.isna(coord_str) or coord_str == '':
        return None, None
    
    try:
        # Debug: Show what we're trying to parse
        print(f"DEBUG: Parsing coordinate string: '{coord_str}'")
        print(f"DEBUG: Length: {len(str(coord_str))}")
        print(f"DEBUG: Repr: {repr(str(coord_str))}")
        
        # Clean the string - remove extra whitespace and invisible characters
        coord_str = re.sub(r'\s+', ' ', str(coord_str).strip())
        coord_str = coord_str.replace('\ufeff', '')  # Remove BOM character if present
        coord_str = coord_str.replace('\u200f', '')  # Remove right-to-left mark
        coord_str = coord_str.replace('\u200e', '')  # Remove left-to-right mark
        
        print(f"DEBUG: After cleaning: '{coord_str}'")
        
        # Check if there's a "/" separator (indicating both DMS and decimal formats)
        if '/' in coord_str:
            print("DEBUG: Found '/' separator, trying decimal part")
            # Split and use the decimal part (after the "/")
            decimal_part = coord_str.split('/')[-1].strip()
            print(f"DEBUG: Decimal part: '{decimal_part}'")
            
            # More flexible pattern for decimal coordinates
            # Matches: 53.43083°N 2.96083°W or 53.43083°N, 2.96083°W
            decimal_patterns = [
                r'(\d+\.?\d*)°([NS])\s+(\d+\.?\d*)°([EW])',
                r'(\d+\.?\d*)°([NS])[,\s]+(\d+\.?\d*)°([EW])',
                r'(\d+\.?\d*)\s*°\s*([NS])\s+(\d+\.?\d*)\s*°\s*([EW])'
            ]
            
            for pattern in decimal_patterns:
                decimal_match = re.search(pattern, decimal_part)
                if decimal_match:
                    print(f"DEBUG: Decimal pattern matched: {decimal_match.groups()}")
                    lat_val, lat_dir, lon_val, lon_dir = decimal_match.groups()
                    lat_decimal = float(lat_val)
                    lon_decimal = float(lon_val)
                    
                    # Apply direction (negative for South/West)
                    if lat_dir == 'S':
                        lat_decimal = -lat_decimal
                    if lon_dir == 'W':
                        lon_decimal = -lon_decimal
                        
                    print(f"DEBUG: Converted to: {lat_decimal}, {lon_decimal}")
                    return lat_decimal, lon_decimal
        
        # Fallback: Try to parse DMS format from the beginning
        print("DEBUG: Trying DMS format")
        # More flexible DMS patterns
        dms_patterns = [
            r'(\d+)°(\d+)′(\d+)″([NS])\s+(\d+)°(\d+)′(\d+)″([EW])',
            r'(\d+)°(\d+)′(\d+)″([NS])[,\s]+(\d+)°(\d+)′(\d+)″([EW])',
            r'(\d+)\s*°\s*(\d+)\s*′\s*(\d+)\s*″\s*([NS])\s+(\d+)\s*°\s*(\d+)\s*′\s*(\d+)\s*″\s*([EW])'
        ]
        
        for pattern in dms_patterns:
            dms_match = re.search(pattern, coord_str)
            if dms_match:
                print(f"DEBUG: DMS pattern matched: {dms_match.groups()}")
                lat_deg, lat_min, lat_sec, lat_dir, lon_deg, lon_min, lon_sec, lon_dir = dms_match.groups()
                
                # Convert to decimal degrees
                lat_decimal = int(lat_deg) + int(lat_min)/60 + int(lat_sec)/3600
                lon_decimal = int(lon_deg) + int(lon_min)/60 + int(lon_sec)/3600
                
                # Apply direction (negative for South/West)
                if lat_dir == 'S':
                    lat_decimal = -lat_decimal
                if lon_dir == 'W':
                    lon_decimal = -lon_decimal
                    
                print(f"DEBUG: Converted to: {lat_decimal}, {lon_decimal}")
                return lat_decimal, lon_decimal
        
        # Last attempt: simple decimal format
        print("DEBUG: Trying simple decimal format")
        simple_patterns = [
            r'([-+]?\d*\.?\d+)[,\s]+([-+]?\d*\.?\d+)',
            r'(\d+\.?\d+)\s*,\s*(\d+\.?\d+)',
            r'(\d+\.?\d+)\s+(\d+\.?\d+)'
        ]
        
        for pattern in simple_patterns:
            simple_match = re.search(pattern, coord_str)
            if simple_match:
                print(f"DEBUG: Simple decimal pattern matched: {simple_match.groups()}")
                lat, lon = simple_match.groups()
                result = float(lat), float(lon)
                print(f"DEBUG: Converted to: {result}")
                return result
        
        print("DEBUG: No patterns matched")
            
    except Exception as e:
        print(f"ERROR parsing coordinates '{coord_str}': {e}")
        
    return None, None

# Debug: Print all column names to see what's available
print("All columns in the dataframe:")
for i, col in enumerate(stadiums_df.columns):
    print(f"{i}: '{col}'")

# Find coordinates column and convert to WGS84
coord_columns = [col for col in stadiums_df.columns if col == 'Coordinates'] 

coord_col = coord_columns[0]  # Use first coordinates column found
print(f"Using coordinates column: '{coord_col}'")

# Debug: Show some raw coordinate values
print(f"\nSample raw coordinate values from '{coord_col}':")
sample_coords = stadiums_df[coord_col].dropna().head(5)
for i, coord in enumerate(sample_coords):
    print(f"{i+1}: '{coord}'")

# Extract and convert coordinates
coords = stadiums_df[coord_col].apply(parse_coordinates)

# Debug: Show parsing results
print(f"\nParsing results (first 5):")
for i, coord in enumerate(coords.head(5)):
    original = stadiums_df[coord_col].iloc[i] if i < len(stadiums_df) else "N/A"
    print(f"{i+1}: '{original}' -> {coord}")

# Create separate latitude and longitude columns
stadiums_df['Latitude_WGS84'] = [coord[0] if coord[0] is not None else None for coord in coords]
stadiums_df['Longitude_WGS84'] = [coord[1] if coord[1] is not None else None for coord in coords]

# Display conversion results
successful_conversions = stadiums_df[['Latitude_WGS84', 'Longitude_WGS84']].dropna()
print(f"\nSuccessfully converted {len(successful_conversions)} coordinates to WGS84 decimal degrees")

if len(successful_conversions) > 0:
    print("\nSample WGS84 coordinates:")
    print(successful_conversions.head())
else:
    print("No coordinates were successfully converted. Check the parsing function.")

# Optional: Display some basic statistics
print(f"\nSample of stadium names:")
if 'Stadium' in stadiums_df.columns:
    print(stadiums_df['Stadium'].head(5).tolist())
elif len(stadiums_df.columns) > 0:
    print(stadiums_df.iloc[:5, 0].tolist())  # First column if 'Stadium' not found
```


```{python}
# Create GeoPandas GeoDataFrame
successful_coords = stadiums_df.dropna(subset=['Latitude_WGS84', 'Longitude_WGS84'])

if len(successful_coords) > 0:
    print(f"\nCreating GeoPandas GeoDataFrame with {len(successful_coords)} stadiums...")
    
    # Create Point geometries from lat/lon coordinates
    geometry = [Point(lon, lat) for lon, lat in zip(successful_coords['Longitude_WGS84'], 
                                                   successful_coords['Latitude_WGS84'])]
    
    # Create GeoDataFrame
    gdf = gpd.GeoDataFrame(successful_coords, geometry=geometry, crs='EPSG:4326')
    
    print(f"GeoPandas GeoDataFrame created successfully!")
    print(f"CRS: {gdf.crs}")
    print(f"Geometry type: {gdf.geometry.geom_type.iloc[0] if len(gdf) > 0 else 'None'}")
    
    # Display basic info about the GeoDataFrame
    print(f"\nGeoDataFrame info:")
    print(f"Shape: {gdf.shape}")
    print(f"Columns: {list(gdf.columns)}")
    
    # Show first few rows with geometry
    print(f"\nFirst few stadiums with coordinates:")
    if 'Stadium' in gdf.columns:
        display_cols = ['Stadium', 'Latitude_WGS84', 'Longitude_WGS84', 'geometry']
        available_cols = [col for col in display_cols if col in gdf.columns]
        print(gdf[available_cols].head())
    else:
        print(gdf[['Latitude_WGS84', 'Longitude_WGS84', 'geometry']].head())
    
    # Optional: Save as GeoJSON
    gdf.to_file('premier_league_stadiums.geojson', driver='GeoJSON')
    print(f"\nGeoDataFrame saved as 'premier_league_stadiums.geojson'")
    
    # Optional: Save as Shapefile
    try:
        gdf.to_file('premier_league_stadiums.shp')
        print(f"GeoDataFrame saved as 'premier_league_stadiums.shp'")
    except Exception as e:
        print(f"Could not save as Shapefile: {e}")
    
    # Calculate bounding box
    bounds = gdf.total_bounds
    print(f"\nBounding box (min_lon, min_lat, max_lon, max_lat): {bounds}")
    
    # Optional: Basic spatial analysis
    print(f"\nBasic spatial info:")
    print(f"Centroid of all stadiums: {gdf.geometry.centroid.iloc[0] if len(gdf) > 0 else 'None'}")
    
    # Return the GeoDataFrame for further use
    stadiums_gdf = gdf
    
else:
    print("No valid coordinates found - cannot create GeoDataFrame")
    stadiums_gdf = None
```


```{python}
# Filter to just stadiums that are currently open
stadiums_gdf = stadiums_gdf.loc[stadiums_gdf['Closed'].isna()]
```

# Plot

```{python}
# Create figure and axis
fig, ax = plt.subplots(figsize=(10, 8))  # Note: subplots, not plt, and figsize should be reasonable

# Plot the stadiums
stadiums_gdf.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)

# Add some styling
ax.set_title('Premier League Stadiums', fontsize=16, fontweight='bold')
ax.set_axis_off()
cx.add_basemap(ax, crs = stadiums_gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)

# Create text objects for labels
# texts = []
# for idx, row in stadiums_gdf.iterrows():
#     text = ax.text(row.geometry.x, row.geometry.y, row['Stadium'],
#                    fontsize=8, ha='center', va='center',
#                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
#     texts.append(text)

# # Adjust text positions to avoid overlaps
# adjust_text(texts, 
#             arrowprops=dict(arrowstyle='->', color='black', lw=0.5),
#             expand_points=(1.2, 1.2),
#             expand_text=(1.2, 1.2))

# Show the plot
plt.tight_layout()
plt.show()
```

```{python}
tott = stadiums_gdf.loc[stadiums_gdf['Stadium'] == 'Tottenham Hotspur Stadium']

fig, ax = plt.subplots(figsize=(10, 8)) 

# Plot the stadiums
tott.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)


# Add some styling
ax.set_title('Premier League Stadiums', fontsize=16, fontweight='bold')


# Get the coordinates
x, y = tott.geometry.x.iloc[0], tott.geometry.y.iloc[0]
# Set reasonable axis limits around the point
margin = 0.01  # Adjust this value to zoom in/out
ax.set_xlim(x - margin, x + margin)
ax.set_ylim(y - margin, y + margin)

ax.set_axis_off()

cx.add_basemap(ax, crs = tott.crs, source=cx.providers.OpenStreetMap.Mapnik)
plt.show()
```


```{python}

file = 'msoa_geometries.pkl'
path = os.path.join('..', 'data', file)
if(os.path.isfile(path)) == False:
    print('Downloading geometries')
    # Get msoa geometries for the whole country
    query = 'SELECT msoa21cd, msoa21nm, geometry FROM msoa21_boundaries'

    with psycopg2.connect(**db_params) as con:
        msoa_gdf = gpd.read_postgis(query, con = con, geom_col='geometry')

    msoa_gdf.to_pickle(path)
else:
    print('Geometries already in directory. Loading.')
    with open(path, 'rb') as file:
        msoa_gdf = pickle.load(file)
```

Use spatial join to locate stadiums in MSOAs

```{python}
points_gdf = gpd.GeoDataFrame(stadiums_gdf[['Stadium', 'geometry']])

# points_gdf = gpd.GeoDataFrame(stadiums_gdf[['geometry']])
points_gdf = points_gdf.to_crs(epsg=27700) # maybe go back to web scraping and redefine the desired crs to 27700

# Spatial join to find which polygon each point falls in
joined = gpd.sjoin(points_gdf, msoa_gdf, how='left', predicate='within')
```

# Finding nearest neighbours

```{python}

import numpy as np
from sklearn.neighbors import BallTree, radius_neighbors_graph
from scipy.spatial import cKDTree


# Get point coordinates (n_targets x 2)
target_coords = np.array([[geom.x, geom.y] for geom in joined.geometry])

# Get MSOA centroid coordinates (n_msoas x 2)
msoa_gdf['centroid'] = msoa_gdf.geometry.centroid
msoa_coords = np.array([[pt.x, pt.y] for pt in msoa_gdf['centroid']])

# Radius in meters
radius_m = 1000

# Build KD-tree for fast spatial query
tree = cKDTree(msoa_coords)

# Query neighbors within radius for each point
neighbors_dict = {}

for i, point in enumerate(target_coords):
    indices = tree.query_ball_point(point, r=radius_m)
    neighbor_codes = msoa_gdf.iloc[indices]['msoa21cd'].tolist()
    point_id = joined.iloc[i].get('Stadium', f'point_{i}')  # Use a unique ID or fallback
    neighbors_dict[point_id] = neighbor_codes


results = []
for i, row in joined.iterrows():
    point_id = row.get('Stadium', f'point_{i}')
    containing_msoa = row['msoa21cd']  # MSOA containing the point (may be NaN if outside)
    neighbors = neighbors_dict.get(point_id, [])
    results.append({
        'stadium': point_id,
        'containing_msoa': containing_msoa,
        'neighboring_msoas': neighbors
    })

```


```{python}
# Collect all MSOA codes from containing_msoa and neighboring_msoas
all_msoas = []

for res in results:
    # Add containing MSOA if it exists and is not None or NaN
    if res['containing_msoa']:
        all_msoas.append(res['containing_msoa'])
    # Add all neighboring MSOAs
    all_msoas.extend(res['neighboring_msoas'])

# Get unique MSOAs by converting to a set, then back to a list if needed
unique_msoas = list(set(all_msoas))

# unique_msoas now holds all unique MSOA codes from both categories
print(unique_msoas)

neighbors_gdf = msoa_gdf.loc[msoa_gdf['msoa21cd'].isin(unique_msoas)]
```

```{python}
# Plot Haringey

haringey = neighbors_gdf.loc[neighbors_gdf['msoa21nm'].str.contains('Haringey')]
tott = tott.to_crs(epsg=27700)

fig, ax = plt.subplots(figsize=[8,8])

haringey.plot(ax=ax, alpha=0.5)
tott.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)
cx.add_basemap(ax, crs = tott.crs, source=cx.providers.OpenStreetMap.Mapnik)

```