---
title: "Untitled"
format: html
---


```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
import contextily as cx
from adjustText import adjust_text
import configparser
import psycopg2
import os
import pickle
import numpy as np
from sklearn.neighbors import BallTree, radius_neighbors_graph
from scipy.spatial import cKDTree
import janitor

config = configparser.ConfigParser()
config.read(os.path.join('..', 'db_config.ini'))

db_params = dict(config['postgresql'])
```

Read the table on wikipedia: [https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums](https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums)

```{python}
# Define the URL
url = "https://en.wikipedia.org/wiki/List_of_Premier_League_stadiums"

# Send GET request to the webpage
response = requests.get(url)
response.raise_for_status()  # Raise an exception for bad status codes

# Parse the HTML content
soup = BeautifulSoup(response.content, 'html.parser')

# Find the first wikitable (which contains the stadiums data)
table = soup.find('table', {'class': 'wikitable'})

# Extract table data using pandas
stadiums_df = pd.read_html(str(table))[0]

# Clean the data
def clean_text(text):
    """Remove Wikipedia reference numbers and extra whitespace"""
    if pd.isna(text):
        return text
    # Remove reference numbers like [1], [2], etc.
    text = re.sub(r'\[.*?\]', '', str(text))
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Apply cleaning to all columns
for col in stadiums_df.columns:
    stadiums_df[col] = stadiums_df[col].apply(clean_text)

# Remove any completely empty rows
stadiums_df = stadiums_df.dropna(how='all')

# Display basic info about the scraped data
print(f"Successfully scraped {len(stadiums_df)} stadiums")
print(f"Columns: {', '.join(stadiums_df.columns)}")
print("\nFirst few rows:")
print(stadiums_df.head())

# Display data types and info
print("\nDataFrame info:")
print(stadiums_df.info())

# Optional: Save to CSV
stadiums_df.to_csv('premier_league_stadiums.csv', index=False)
print("\nData saved to 'premier_league_stadiums.csv'")

# Parse the coordinates into usable WGS64 geometries
def parse_coordinates(coord_str):
    """
    Convert coordinates to decimal degrees (WGS84)
    Handles format: 53°25′51″N 002°57′39″W﻿ / ﻿53.43083°N 2.96083°W
    """
    if pd.isna(coord_str) or coord_str == '':
        return None, None
    
    try:
        # Debug: Show what we're trying to parse
        print(f"DEBUG: Parsing coordinate string: '{coord_str}'")
        print(f"DEBUG: Length: {len(str(coord_str))}")
        print(f"DEBUG: Repr: {repr(str(coord_str))}")
        
        # Clean the string - remove extra whitespace and invisible characters
        coord_str = re.sub(r'\s+', ' ', str(coord_str).strip())
        coord_str = coord_str.replace('\ufeff', '')  # Remove BOM character if present
        coord_str = coord_str.replace('\u200f', '')  # Remove right-to-left mark
        coord_str = coord_str.replace('\u200e', '')  # Remove left-to-right mark
        
        print(f"DEBUG: After cleaning: '{coord_str}'")
        
        # Check if there's a "/" separator (indicating both DMS and decimal formats)
        if '/' in coord_str:
            print("DEBUG: Found '/' separator, trying decimal part")
            # Split and use the decimal part (after the "/")
            decimal_part = coord_str.split('/')[-1].strip()
            print(f"DEBUG: Decimal part: '{decimal_part}'")
            
            # More flexible pattern for decimal coordinates
            # Matches: 53.43083°N 2.96083°W or 53.43083°N, 2.96083°W
            decimal_patterns = [
                r'(\d+\.?\d*)°([NS])\s+(\d+\.?\d*)°([EW])',
                r'(\d+\.?\d*)°([NS])[,\s]+(\d+\.?\d*)°([EW])',
                r'(\d+\.?\d*)\s*°\s*([NS])\s+(\d+\.?\d*)\s*°\s*([EW])'
            ]
            
            for pattern in decimal_patterns:
                decimal_match = re.search(pattern, decimal_part)
                if decimal_match:
                    print(f"DEBUG: Decimal pattern matched: {decimal_match.groups()}")
                    lat_val, lat_dir, lon_val, lon_dir = decimal_match.groups()
                    lat_decimal = float(lat_val)
                    lon_decimal = float(lon_val)
                    
                    # Apply direction (negative for South/West)
                    if lat_dir == 'S':
                        lat_decimal = -lat_decimal
                    if lon_dir == 'W':
                        lon_decimal = -lon_decimal
                        
                    print(f"DEBUG: Converted to: {lat_decimal}, {lon_decimal}")
                    return lat_decimal, lon_decimal
        
        # Fallback: Try to parse DMS format from the beginning
        print("DEBUG: Trying DMS format")
        # More flexible DMS patterns
        dms_patterns = [
            r'(\d+)°(\d+)′(\d+)″([NS])\s+(\d+)°(\d+)′(\d+)″([EW])',
            r'(\d+)°(\d+)′(\d+)″([NS])[,\s]+(\d+)°(\d+)′(\d+)″([EW])',
            r'(\d+)\s*°\s*(\d+)\s*′\s*(\d+)\s*″\s*([NS])\s+(\d+)\s*°\s*(\d+)\s*′\s*(\d+)\s*″\s*([EW])'
        ]
        
        for pattern in dms_patterns:
            dms_match = re.search(pattern, coord_str)
            if dms_match:
                print(f"DEBUG: DMS pattern matched: {dms_match.groups()}")
                lat_deg, lat_min, lat_sec, lat_dir, lon_deg, lon_min, lon_sec, lon_dir = dms_match.groups()
                
                # Convert to decimal degrees
                lat_decimal = int(lat_deg) + int(lat_min)/60 + int(lat_sec)/3600
                lon_decimal = int(lon_deg) + int(lon_min)/60 + int(lon_sec)/3600
                
                # Apply direction (negative for South/West)
                if lat_dir == 'S':
                    lat_decimal = -lat_decimal
                if lon_dir == 'W':
                    lon_decimal = -lon_decimal
                    
                print(f"DEBUG: Converted to: {lat_decimal}, {lon_decimal}")
                return lat_decimal, lon_decimal
        
        # Last attempt: simple decimal format
        print("DEBUG: Trying simple decimal format")
        simple_patterns = [
            r'([-+]?\d*\.?\d+)[,\s]+([-+]?\d*\.?\d+)',
            r'(\d+\.?\d+)\s*,\s*(\d+\.?\d+)',
            r'(\d+\.?\d+)\s+(\d+\.?\d+)'
        ]
        
        for pattern in simple_patterns:
            simple_match = re.search(pattern, coord_str)
            if simple_match:
                print(f"DEBUG: Simple decimal pattern matched: {simple_match.groups()}")
                lat, lon = simple_match.groups()
                result = float(lat), float(lon)
                print(f"DEBUG: Converted to: {result}")
                return result
        
        print("DEBUG: No patterns matched")
            
    except Exception as e:
        print(f"ERROR parsing coordinates '{coord_str}': {e}")
        
    return None, None

# Debug: Print all column names to see what's available
print("All columns in the dataframe:")
for i, col in enumerate(stadiums_df.columns):
    print(f"{i}: '{col}'")

# Find coordinates column and convert to WGS84
coord_columns = [col for col in stadiums_df.columns if col == 'Coordinates'] 

coord_col = coord_columns[0]  # Use first coordinates column found
print(f"Using coordinates column: '{coord_col}'")

# Debug: Show some raw coordinate values
print(f"\nSample raw coordinate values from '{coord_col}':")
sample_coords = stadiums_df[coord_col].dropna().head(5)
for i, coord in enumerate(sample_coords):
    print(f"{i+1}: '{coord}'")

# Extract and convert coordinates
coords = stadiums_df[coord_col].apply(parse_coordinates)

# Debug: Show parsing results
print(f"\nParsing results (first 5):")
for i, coord in enumerate(coords.head(5)):
    original = stadiums_df[coord_col].iloc[i] if i < len(stadiums_df) else "N/A"
    print(f"{i+1}: '{original}' -> {coord}")

# Create separate latitude and longitude columns
stadiums_df['Latitude_WGS84'] = [coord[0] if coord[0] is not None else None for coord in coords]
stadiums_df['Longitude_WGS84'] = [coord[1] if coord[1] is not None else None for coord in coords]

# Display conversion results
successful_conversions = stadiums_df[['Latitude_WGS84', 'Longitude_WGS84']].dropna()
print(f"\nSuccessfully converted {len(successful_conversions)} coordinates to WGS84 decimal degrees")

if len(successful_conversions) > 0:
    print("\nSample WGS84 coordinates:")
    print(successful_conversions.head())
else:
    print("No coordinates were successfully converted. Check the parsing function.")

# Optional: Display some basic statistics
print(f"\nSample of stadium names:")
if 'Stadium' in stadiums_df.columns:
    print(stadiums_df['Stadium'].head(5).tolist())
elif len(stadiums_df.columns) > 0:
    print(stadiums_df.iloc[:5, 0].tolist())  # First column if 'Stadium' not found
```


```{python}
# Create GeoPandas GeoDataFrame
successful_coords = stadiums_df.dropna(subset=['Latitude_WGS84', 'Longitude_WGS84'])

if len(successful_coords) > 0:
    print(f"\nCreating GeoPandas GeoDataFrame with {len(successful_coords)} stadiums...")
    
    # Create Point geometries from lat/lon coordinates
    geometry = [Point(lon, lat) for lon, lat in zip(successful_coords['Longitude_WGS84'], 
                                                   successful_coords['Latitude_WGS84'])]
    
    # Create GeoDataFrame
    gdf = gpd.GeoDataFrame(successful_coords, geometry=geometry, crs='EPSG:4326')
    
    print(f"GeoPandas GeoDataFrame created successfully!")
    print(f"CRS: {gdf.crs}")
    print(f"Geometry type: {gdf.geometry.geom_type.iloc[0] if len(gdf) > 0 else 'None'}")
    
    # Display basic info about the GeoDataFrame
    print(f"\nGeoDataFrame info:")
    print(f"Shape: {gdf.shape}")
    print(f"Columns: {list(gdf.columns)}")
    
    # Show first few rows with geometry
    print(f"\nFirst few stadiums with coordinates:")
    if 'Stadium' in gdf.columns:
        display_cols = ['Stadium', 'Latitude_WGS84', 'Longitude_WGS84', 'geometry']
        available_cols = [col for col in display_cols if col in gdf.columns]
        print(gdf[available_cols].head())
    else:
        print(gdf[['Latitude_WGS84', 'Longitude_WGS84', 'geometry']].head())
    
    # Optional: Save as GeoJSON
    gdf.to_file('premier_league_stadiums.geojson', driver='GeoJSON')
    print(f"\nGeoDataFrame saved as 'premier_league_stadiums.geojson'")
    
    # Optional: Save as Shapefile
    try:
        gdf.to_file('premier_league_stadiums.shp')
        print(f"GeoDataFrame saved as 'premier_league_stadiums.shp'")
    except Exception as e:
        print(f"Could not save as Shapefile: {e}")
    
    # Calculate bounding box
    bounds = gdf.total_bounds
    print(f"\nBounding box (min_lon, min_lat, max_lon, max_lat): {bounds}")
    
    # Optional: Basic spatial analysis
    print(f"\nBasic spatial info:")
    print(f"Centroid of all stadiums: {gdf.geometry.centroid.iloc[0] if len(gdf) > 0 else 'None'}")
    
    # Return the GeoDataFrame for further use
    stadiums_gdf = gdf
    
else:
    print("No valid coordinates found - cannot create GeoDataFrame")
    stadiums_gdf = None
```


```{python}
# Filter to just stadiums that are currently open
stadiums_gdf = stadiums_gdf.loc[stadiums_gdf['Closed'].isna()]
```

# Plot

```{python}
# Create figure and axis
fig, ax = plt.subplots(figsize=(10, 8))  # Note: subplots, not plt, and figsize should be reasonable

# Plot the stadiums
stadiums_gdf.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)

# Add some styling
ax.set_title('Premier League Stadiums', fontsize=16, fontweight='bold')
ax.set_axis_off()
cx.add_basemap(ax, crs = stadiums_gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)

# Create text objects for labels
# texts = []
# for idx, row in stadiums_gdf.iterrows():
#     text = ax.text(row.geometry.x, row.geometry.y, row['Stadium'],
#                    fontsize=8, ha='center', va='center',
#                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
#     texts.append(text)

# # Adjust text positions to avoid overlaps
# adjust_text(texts, 
#             arrowprops=dict(arrowstyle='->', color='black', lw=0.5),
#             expand_points=(1.2, 1.2),
#             expand_text=(1.2, 1.2))

# Show the plot
plt.tight_layout()
plt.show()
```

```{python}
tott = stadiums_gdf.loc[stadiums_gdf['Stadium'] == 'Tottenham Hotspur Stadium']

fig, ax = plt.subplots(figsize=(10, 8)) 

# Plot the stadiums
tott.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)


# Add some styling
ax.set_title('Premier League Stadiums', fontsize=16, fontweight='bold')


# Get the coordinates
x, y = tott.geometry.x.iloc[0], tott.geometry.y.iloc[0]
# Set reasonable axis limits around the point
margin = 0.01  # Adjust this value to zoom in/out
ax.set_xlim(x - margin, x + margin)
ax.set_ylim(y - margin, y + margin)

ax.set_axis_off()

cx.add_basemap(ax, crs = tott.crs, source=cx.providers.OpenStreetMap.Mapnik)
plt.show()
```


```{python}

file = 'msoa_geometries.pkl'
path = os.path.join('..', 'data', file)
if(os.path.isfile(path)) == False:
    print('Downloading geometries')
    # Get msoa geometries for the whole country
    query = 'SELECT msoa21cd, msoa21nm, geometry FROM msoa21_boundaries'

    with psycopg2.connect(**db_params) as con:
        msoa_gdf = gpd.read_postgis(query, con = con, geom_col='geometry')

    msoa_gdf.to_pickle(path)
else:
    print('Geometries already in directory. Loading.')
    with open(path, 'rb') as file:
        msoa_gdf = pickle.load(file)
```

Use spatial join to locate stadiums in MSOAs

```{python}
points_gdf = gpd.GeoDataFrame(stadiums_gdf[['Stadium', 'geometry']])

# points_gdf = gpd.GeoDataFrame(stadiums_gdf[['geometry']])
points_gdf = points_gdf.to_crs(epsg=27700) # maybe go back to web scraping and redefine the desired crs to 27700

# Spatial join to find which polygon each point falls in
joined = gpd.sjoin(points_gdf, msoa_gdf, how='left', predicate='within')
```

# Finding nearest neighbours

```{python}
# Get point coordinates (n_targets x 2)
target_coords = np.array([[geom.x, geom.y] for geom in joined.geometry])

# Get MSOA centroid coordinates (n_msoas x 2)
msoa_gdf['centroid'] = msoa_gdf.geometry.centroid
msoa_coords = np.array([[pt.x, pt.y] for pt in msoa_gdf['centroid']])

# Radius in meters
radius_m = 1000

# Build KD-tree for fast spatial query
tree = cKDTree(msoa_coords)

# Query neighbors within radius for each point
neighbors_dict = {}

for i, point in enumerate(target_coords):
    indices = tree.query_ball_point(point, r=radius_m)
    neighbor_codes = msoa_gdf.iloc[indices]['msoa21cd'].tolist()
    point_id = joined.iloc[i].get('Stadium', f'point_{i}')  # Use a unique ID or fallback
    neighbors_dict[point_id] = neighbor_codes


results = []
for i, row in joined.iterrows():
    point_id = row.get('Stadium', f'point_{i}')
    containing_msoa = row['msoa21cd']  # MSOA containing the point (may be NaN if outside)
    neighbors = neighbors_dict.get(point_id, [])
    results.append({
        'stadium': point_id,
        'containing_msoa': containing_msoa,
        'neighboring_msoas': neighbors
    })

```

```{python}
# Get point coordinates (n_targets x 2)
target_coords = np.array([[geom.x, geom.y] for geom in joined.geometry])

# Radius in meters
radius_m = 1000

# Method 1: Using buffer and intersects (Recommended - most accurate)
neighbors_dict = {}
for i, row in joined.iterrows():
    point_geom = row.geometry
    point_id = row.get('Stadium', f'point_{i}')
    
    # Create buffer around the point
    point_buffer = point_geom.buffer(radius_m)
    
    # Find all MSOAs that intersect with the buffer
    intersecting_msoas = msoa_gdf[msoa_gdf.geometry.intersects(point_buffer)]
    neighbor_codes = intersecting_msoas['msoa21cd'].tolist()
    
    neighbors_dict[point_id] = neighbor_codes

# Alternative Method 2: Using distance calculation (also accurate but potentially slower)
# Uncomment below if you prefer this approach:

# neighbors_dict = {}
# for i, row in joined.iterrows():
#     point_geom = row.geometry
#     point_id = row.get('Stadium', f'point_{i}')
#     
#     # Calculate distance from point to each MSOA geometry
#     distances = msoa_gdf.geometry.distance(point_geom)
#     
#     # Find MSOAs within the radius
#     within_radius = distances <= radius_m
#     neighbor_codes = msoa_gdf[within_radius]['msoa21cd'].tolist()
#     
#     neighbors_dict[point_id] = neighbor_codes

# Rest of your code remains the same
results = []
for i, row in joined.iterrows():
    point_id = row.get('Stadium', f'point_{i}')
    containing_msoa = row['msoa21cd']  # MSOA containing the point (may be NaN if outside)
    neighbors = neighbors_dict.get(point_id, [])
    results.append({
        'stadium': point_id,
        'containing_msoa': containing_msoa,
        'neighboring_msoas': neighbors
    })
```

```{python}
# # Collect all MSOA codes from containing_msoa and neighboring_msoas
# all_msoas = []

# for res in results:
#     # Add containing MSOA if it exists and is not None or NaN
#     if res['containing_msoa']:
#         all_msoas.append(res['containing_msoa'])
#     # Add all neighboring MSOAs
#     all_msoas.extend(res['neighboring_msoas'])

# # Get unique MSOAs by converting to a set, then back to a list if needed
# unique_msoas = list(set(all_msoas))

# # unique_msoas now holds all unique MSOA codes from both categories
# print(unique_msoas)

# neighbors_gdf = msoa_gdf.loc[msoa_gdf['msoa21cd'].isin(unique_msoas)]
```

```{python}
from collections import defaultdict
# Step 1: Build a mapping from MSOA to associated stadium(s)
msoa_to_stadiums = defaultdict(set)
for res in results:
    stadium = res['stadium']
    if res['containing_msoa']:
        msoa_to_stadiums[res['containing_msoa']].add(stadium)
    for neighbor in res['neighboring_msoas']:
        # print(neighbor)
        msoa_to_stadiums[neighbor].add(stadium)

# Step 2: Flatten the mapping into a DataFrame
msoa_stadium_rows = []
for msoa, stadiums in msoa_to_stadiums.items():
    for stadium in stadiums:
        msoa_stadium_rows.append({
            'msoa21cd': msoa,
            'stadium': stadium
        })

msoa_stadium_df = pd.DataFrame(msoa_stadium_rows)

# Step 3: Join this info with the original MSOA GeoDataFrame
neighbors_gdf = msoa_gdf.merge(msoa_stadium_df, on='msoa21cd', how='inner')
```

```{python}
# Plot Haringey to check
haringey = neighbors_gdf.loc[neighbors_gdf['msoa21nm'].str.contains('Haringey')]
tott = tott.to_crs(epsg=27700)

fig, ax = plt.subplots(figsize=[8,8])

haringey.plot(ax=ax, alpha=0.5, edgecolor="black")
tott.plot(ax=ax, marker='o', color='red', markersize=50, alpha=0.7)
cx.add_basemap(ax, crs = tott.crs, source=cx.providers.OpenStreetMap.Mapnik)

```

# Child poverty data

```{python}
relative = pd.read_csv(os.path.join('..','data','relative_low_income_msoa.csv'), skiprows=9)

relative = relative.iloc[:,[1,3]]
relative.columns = ['msoa_name','count']

absolute = pd.read_csv(os.path.join('..','data','absolute_low_income_msoa.csv'), skiprows=9)

absolute = absolute.iloc[:,[1,3]]
absolute.columns = ['msoa_name','count']
```

```{python}
# Get population estimates by age (thank you Ollie for having this in db!)

with psycopg2.connect(**db_params) as con:
    query = '''
            SELECT msoa21nm, msoa21cd, SUM(count) AS population
            FROM census21_msoa_population_by_age 
            WHERE age < 20
            GROUP BY msoa21nm, msoa21cd
    '''
    pop_ests = pd.read_sql(query, con=con)


```


```{python}
# Join pop ests to CILIF data
# Relative
relative2 = (relative
            .merge(pop_ests, how = 'left', left_on='msoa_name', right_on='msoa21nm')
            .drop(columns='msoa_name')
)

# Move count to a better location
cols = list(relative2.columns)
cols.remove('count')
insert_at = cols.index('population')
cols.insert(insert_at, 'count')

relative2 = relative2[cols]

relative2['percentage'] = relative2['count'].div(relative2['population'])*100
relative2['decile'] = pd.qcut(relative2['percentage'], q=10, labels=list(range(10,0,-1)), duplicates='drop')
relative2['decile'] = pd.to_numeric(relative2['decile'], errors='coerce')

# Absolute
absolute2 = (absolute
            .merge(pop_ests, how = 'left', left_on='msoa_name', right_on='msoa21nm')
            .drop(columns='msoa_name')
)

# Move count to a better location
cols = list(absolute2.columns)
cols.remove('count')
insert_at = cols.index('population')
cols.insert(insert_at, 'count')

absolute2 = absolute2[cols]

absolute2['percentage'] = absolute2['count'].div(absolute2['population'])*100
absolute2['decile'] = pd.qcut(absolute2['percentage'], q=10, labels=list(range(10,0,-1)), duplicates='drop') 
absolute2['decile'] = pd.to_numeric(absolute2['decile'], errors='coerce')

```

# Join neighbours with CILIF

```{python}
neighbors_gdf2 = (neighbors_gdf
                  .merge(relative2.loc[:,['msoa21nm','percentage','decile']], how='left', on='msoa21nm')
                  .rename(columns={
                    'percentage':'relative_percentage',
                    'decile': 'relative_decile'})
                  .merge(absolute2.loc[:,['msoa21nm','percentage','decile']], how='left', on='msoa21nm')
                  .rename(columns={
                    'percentage':'absolute_percentage',
                    'decile': 'absolute_decile'})
                  .sort_values(by='msoa21nm')
)
```


```{python}
stadiums_gdf2 = stadiums_gdf.to_crs(epsg=27700)
temp = neighbors_gdf.loc[neighbors_gdf['stadium'].isin(['Anfield', 'Tottenham Hotspur Stadium'])]
# for stadium in temp['stadium'].unique():
for stadium in neighbors_gdf2['stadium'].unique():
    # print(stadium)

    msoa_temp_gdf = neighbors_gdf2.loc[neighbors_gdf2['stadium']==stadium]
    stadiums_temp_gdf = stadiums_gdf2.loc[stadiums_gdf2['Stadium']==stadium]

    fig, ax = plt.subplots(figsize=[8,8])
    msoa_temp_gdf.plot(ax=ax,column='relative_decile', edgecolor="black", legend = True,
    legend_kwds={'label': 'Decile'}, 
    vmin=1, vmax=10,
    alpha = 0.5)
    stadiums_temp_gdf.plot(ax=ax, color="red")
    plt.title(stadium)
    cx.add_basemap(ax, crs = msoa_temp_gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)
    ax.set_axis_off()


```


```{python}
decile_boundaries = relative2['percentage'].quantile([i/10 for i in range(0, 11)]).tolist()

neighbors_gdf2.loc[neighbors_gdf2['msoa21nm'].str.contains('Northumberland')]
fig, ax = plt.subplots(figsize=[9,9])

# Plot grey points first (bottom layer)
ax.scatter(neighbors_gdf2['relative_percentage'], neighbors_gdf2['stadium'], c='black')

# Add vertical lines for decile boundaries
for i, boundary in enumerate(decile_boundaries):
    ax.axvline(
        x=boundary, 
        color='red', 
        # linestyle=(0, (5, 10)), 
        linestyle='dotted', 
        alpha=0.7)
    if i < 10:
        x_loc = (decile_boundaries[i] + decile_boundaries[i+1]) / 2
        ax.text(x=x_loc, y=ax.get_ylim()[0]*1.2, s=i+1, ha='center')

ax.text(x=ax.get_xlim()[0], y=ax.get_ylim()[0]*1.2, s='Decile', ha='right')

# plt.figtext(0.38, 0.0015, 'Black dots indicate Northumberland Park LSOAs', wrap=False, horizontalalignment='right', fontsize=10)
ax.invert_yaxis()
plt.tight_layout()
# Add title with specific positioning
fig.suptitle('Deprivation in Haringey', fontsize=14, x = 0.7, y=1.03, ha='center')  # y controls vertical position
fig.savefig(os.path.join('..','outputs','deprivation.png'), dpi=300)
plt.show()

```

Maybe rank above instead? could be nicer way of looking at it

grey out non tottenham

highlight northumberland park msoa


An MSOA in Middlesbrough has a child poverty rate higher than the child population. how the heck is this possible? Yeah it seems liek this is really deprived place - 40% of households are deprived in one dimension (https://www.ons.gov.uk/census/maps/choropleth/population/household-deprivation/hh-deprivation/household-is-deprived-in-one-dimension?geoLock=msoa&msoa=E02002498)

It is also the case that the child pvoerty data includes children up to 19 years of age whereas teh population estimates i've used are under 18. maybe this adjustment alone will help the percnetages make more sense. making this change does indeed prevenet percentages > 100 thankfully

More generally I think we need to decide what age groups to focus on.


```{python}
# investigate the high percentage areas
subset = relative2.loc[relative2['percentage']>100]

subset = relative2.loc[relative2['msoa21nm']=="Middlesbrough 003"]

```